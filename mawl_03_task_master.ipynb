{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8409646-1b31-490f-b0d7-25a5501c3387",
   "metadata": {},
   "source": [
    "# Multi-Agentic Workflow with LangGraph\n",
    "\n",
    "## TRUSTCALL VISIBILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d282f77f-e474-4bbf-b9e0-5000d167cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5736b519-bbe9-474d-97c6-1241de80651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Inspect the tool calls made by Trustcall\n",
    "class Spy:\n",
    "    def __init__(self):\n",
    "        self.called_tools = []\n",
    "\n",
    "    def __call__(self, run):\n",
    "        # Collect information about the tool calls made by the extractor.\n",
    "        q = [run]\n",
    "        while q:\n",
    "            r = q.pop()\n",
    "            if r.child_runs:\n",
    "                q.extend(r.child_runs)\n",
    "            if r.run_type == \"chat_model\":\n",
    "                self.called_tools.append(\n",
    "                    r.outputs[\"generations\"][0][0][\"message\"][\"kwargs\"][\"tool_calls\"]\n",
    "                )\n",
    "\n",
    "# Initialize the spy\n",
    "spy = Spy()\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "# Add the spy as a listener\n",
    "trustcall_extractor_see_all_tool_calls = trustcall_extractor.with_listeners(on_end=spy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e020a0f-8cc7-4794-af4b-47e46138b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instruction\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "\n",
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Dd.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Dd.\"), \n",
    "                HumanMessage(content=\"This morning I had a nice bike ride in San Antonio, Texas.\")]\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a2af027-9d4d-441a-8a5c-477c128ca4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_vZATECBEKRB3RarHL6PldIrb)\n",
      " Call ID: call_vZATECBEKRB3RarHL6PldIrb\n",
      "  Args:\n",
      "    content: User had a nice bike ride in San Antonio, Texas this morning.\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07741ba1-882f-4c38-b98a-6dccb76cae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='User had a nice bike ride in San Antonio, Texas this morning.'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca1199b-d0e2-4e1c-800d-0bfa4db2bc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_vZATECBEKRB3RarHL6PldIrb'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35ee0a53-8f22-4aef-bcfb-f36a2a6b6fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Memory',\n",
       "  {'content': 'User had a nice bike ride in San Antonio, Texas this morning.'})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [AIMessage(content=\"That's great, what did you do after?\"), \n",
    "                        HumanMessage(content=\"I went to El Guacamole and ate some carne asada mini tacos.\"),                        \n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking about getting a job soon!\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and value\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d2db276-6551-497d-93ec-22cab8e58746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor_see_all_tool_calls.invoke({\"messages\": updated_conversation, \n",
    "                                                        \"existing\": existing_memories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aef573a-c361-48e4-9eca-ceaf5a43b49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_4RRpVw8OOZOtbesQCvoqQgBu', 'json_doc_id': '0'}\n",
      "{'id': 'call_b0G1uQkFBa0uv94ziHcQwAbn'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d31ca5e8-bb02-47b6-84f8-222b80ea8dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_4RRpVw8OOZOtbesQCvoqQgBu)\n",
      " Call ID: call_4RRpVw8OOZOtbesQCvoqQgBu\n",
      "  Args:\n",
      "    content: User had a nice bike ride in San Antonio, Texas this morning. After the ride, they went to El Guacamole and ate some carne asada mini tacos.\n",
      "  Memory (call_b0G1uQkFBa0uv94ziHcQwAbn)\n",
      " Call ID: call_b0G1uQkFBa0uv94ziHcQwAbn\n",
      "  Args:\n",
      "    content: User is thinking about getting a job soon.\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdbfbbf4-e6e7-4493-afa4-522a6c70f0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='User had a nice bike ride in San Antonio, Texas this morning. After the ride, they went to El Guacamole and ate some carne asada mini tacos.'\n",
      "content='User is thinking about getting a job soon.'\n"
     ]
    }
   ],
   "source": [
    "# Parsed responses\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95f1b2a3-4cd4-4f9d-a4d1-a4c19b01fe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'name': 'PatchDoc',\n",
       "   'args': {'json_doc_id': '0',\n",
       "    'planned_edits': 'Add a new memory entry about the user eating carne asada mini tacos at El Guacamole after their bike ride.',\n",
       "    'patches': [{'op': 'replace',\n",
       "      'path': '/content',\n",
       "      'value': 'User had a nice bike ride in San Antonio, Texas this morning. After the ride, they went to El Guacamole and ate some carne asada mini tacos.'}]},\n",
       "   'id': 'call_4RRpVw8OOZOtbesQCvoqQgBu',\n",
       "   'type': 'tool_call'},\n",
       "  {'name': 'Memory',\n",
       "   'args': {'content': 'User is thinking about getting a job soon.'},\n",
       "   'id': 'call_b0G1uQkFBa0uv94ziHcQwAbn',\n",
       "   'type': 'tool_call'}]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the tool calls made by Trustcall\n",
    "spy.called_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b77619a-fb30-4599-b613-b9cbf8193347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 updated:\n",
      "Plan: Add a new memory entry about the user eating carne asada mini tacos at El Guacamole after their bike ride.\n",
      "Added content: User had a nice bike ride in San Antonio, Texas this morning. After the ride, they went to El Guacamole and ate some carne asada mini tacos.\n",
      "\n",
      "New Memory created:\n",
      "Content: {'content': 'User is thinking about getting a job soon.'}\n"
     ]
    }
   ],
   "source": [
    "def extract_tool_info(tool_calls, schema_name=\"Memory\"):\n",
    "    \"\"\"Extract information from tool calls for both patches and new memories.\n",
    "    \n",
    "    Args:\n",
    "        tool_calls: List of tool calls from the model\n",
    "        schema_name: Name of the schema tool (e.g., \"Memory\", \"ToDo\", \"Profile\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize list of changes\n",
    "    changes = []\n",
    "    \n",
    "    for call_group in tool_calls:\n",
    "        for call in call_group:\n",
    "            if call['name'] == 'PatchDoc':\n",
    "                changes.append({\n",
    "                    'type': 'update',\n",
    "                    'doc_id': call['args']['json_doc_id'],\n",
    "                    'planned_edits': call['args']['planned_edits'],\n",
    "                    'value': call['args']['patches'][0]['value']\n",
    "                })\n",
    "            elif call['name'] == schema_name:\n",
    "                changes.append({\n",
    "                    'type': 'new',\n",
    "                    'value': call['args']\n",
    "                })\n",
    "\n",
    "    # Format results as a single string\n",
    "    result_parts = []\n",
    "    for change in changes:\n",
    "        if change['type'] == 'update':\n",
    "            result_parts.append(\n",
    "                f\"Document {change['doc_id']} updated:\\n\"\n",
    "                f\"Plan: {change['planned_edits']}\\n\"\n",
    "                f\"Added content: {change['value']}\"\n",
    "            )\n",
    "        else:\n",
    "            result_parts.append(\n",
    "                f\"New {schema_name} created:\\n\"\n",
    "                f\"Content: {change['value']}\"\n",
    "            )\n",
    "    \n",
    "    return \"\\n\\n\".join(result_parts)\n",
    "\n",
    "# Inspect spy.called_tools to see exactly what happened during the extraction\n",
    "schema_name = \"Memory\"\n",
    "changes = extract_tool_info(spy.called_tools, schema_name)\n",
    "print(changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc47efd-c639-4136-bb35-e6c1797e7901",
   "metadata": {},
   "source": [
    "## REACT AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bb20baa-5da6-4cbb-9e59-657e0e5c4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "\n",
    "# Update memory tool\n",
    "class UpdateMemory(TypedDict):\n",
    "    \"\"\" Decision on what memory type to update \"\"\"\n",
    "    update_type: Literal['user', 'todo', 'instructions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48099298-8be8-4860-b11d-f2d6bc0def76",
   "metadata": {},
   "source": [
    "## GRAPH DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8988a2fe-2e53-4ef0-b794-7b5950a5a3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from datetime import datetime\n",
    "from trustcall import create_extractor\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import merge_message_runs, HumanMessage, SystemMessage\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, END, START\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# User profile schema\n",
    "class Profile(BaseModel):\n",
    "    \"\"\"This is the profile of the user you are chatting with\"\"\"\n",
    "    name: Optional[str] = Field(description=\"The user's name\", default=None)\n",
    "    location: Optional[str] = Field(description=\"The user's location\", default=None)\n",
    "    job: Optional[str] = Field(description=\"The user's job\", default=None)\n",
    "    connections: list[str] = Field(\n",
    "        description=\"Personal connection of the user, such as family members, friends, or coworkers\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    interests: list[str] = Field(\n",
    "        description=\"Interests that the user has\", \n",
    "        default_factory=list\n",
    "    )\n",
    "\n",
    "# ToDo schema\n",
    "class ToDo(BaseModel):\n",
    "    task: str = Field(description=\"The task to be completed.\")\n",
    "    mode: Literal[\"anywhere\", \"errand\", \"home\", \"online\", \"phone\"] = Field(\n",
    "        description=\"How the task can be completed.\",\n",
    "        default=\"anywhere\"\n",
    "    )\n",
    "    time_to_complete: Optional[int] = Field(description=\"Estimated time to complete the task (minutes).\")\n",
    "    deadline: Optional[datetime] = Field(\n",
    "        description=\"When the task needs to be completed by (if applicable)\",\n",
    "        default=None\n",
    "    )\n",
    "    location: Optional[str] = Field(\n",
    "        description=\"Where the task can be completed.\",\n",
    "        default=None\n",
    "    )\n",
    "    bizhours_flag: Optional[bool] = Field(\n",
    "        description=\"Whether the task needs to be completed during business hours during the day or not.\",\n",
    "        default=False\n",
    "    )\n",
    "    solutions: list[str] = Field(\n",
    "        description=\"List of specific, actionable solutions (e.g., specific ideas, service providers, or concrete options relevant to completing the task)\",\n",
    "        min_items=1,\n",
    "        default_factory=list\n",
    "    )\n",
    "    status: Literal[\"not started\", \"in progress\", \"done\", \"archived\"] = Field(\n",
    "        description=\"Current status of the task\",\n",
    "        default=\"not started\"\n",
    "    )\n",
    "\n",
    "# Create the Trustcall extractor for updating the user profile \n",
    "profile_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Profile],\n",
    "    tool_choice=\"Profile\",\n",
    ")\n",
    "\n",
    "# Chatbot instruction for choosing what to update and what tools to call \n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot. \n",
    "\n",
    "You are designed to be a companion to a user, helping them keep track of their ToDo list.\n",
    "\n",
    "You have a long term memory which keeps track of three things:\n",
    "1. The user's profile (general information about them) \n",
    "2. The user's ToDo list\n",
    "3. General instructions for updating the ToDo list\n",
    "\n",
    "Here is the current User Profile (may be empty if no information has been collected yet):\n",
    "<user_profile>\n",
    "{user_profile}\n",
    "</user_profile>\n",
    "\n",
    "Here is the current ToDo List (may be empty if no tasks have been added yet):\n",
    "<todo>\n",
    "{todo}\n",
    "</todo>\n",
    "\n",
    "Here are the current user-specified preferences for updating the ToDo list (may be empty if no preferences have been specified yet):\n",
    "<instructions>\n",
    "{instructions}\n",
    "</instructions>\n",
    "\n",
    "Here are your instructions for reasoning about the user's messages:\n",
    "\n",
    "1. Reason carefully about the user's messages as presented below. \n",
    "\n",
    "2. Decide whether any of the your long-term memory should be updated:\n",
    "- If personal information was provided about the user, update the user's profile by calling UpdateMemory tool with type `user`\n",
    "- If tasks are mentioned, update the ToDo list by calling UpdateMemory tool with type `todo`\n",
    "- If the user has specified preferences for how to update the ToDo list, update the instructions by calling UpdateMemory tool with type `instructions`\n",
    "\n",
    "3. Tell the user that you have updated your memory, if appropriate:\n",
    "- Do not tell the user you have updated the user's profile\n",
    "- Tell the user them when you update the todo list\n",
    "- Do not tell the user that you have updated instructions\n",
    "\n",
    "4. Err on the side of updating the todo list. No need to ask for explicit permission.\n",
    "\n",
    "5. Respond naturally to user user after a tool call was made to save memories, or if no tool call was made.\"\"\"\n",
    "\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction. \n",
    "\n",
    "Use the provided tools to retain any necessary memories about the user. \n",
    "\n",
    "Use parallel tool calling to handle updates and insertions simultaneously.\n",
    "\n",
    "System Time: {time}\"\"\"\n",
    "\n",
    "# Instructions for updating the ToDo list\n",
    "CREATE_INSTRUCTIONS = \"\"\"Reflect on the following interaction.\n",
    "\n",
    "Based on this interaction, update your instructions for how to update ToDo list items. \n",
    "\n",
    "Use any feedback from the user to update how they like to have items added, etc.\n",
    "\n",
    "Your current instructions are:\n",
    "\n",
    "<current_instructions>\n",
    "{current_instructions}\n",
    "</current_instructions>\"\"\"\n",
    "\n",
    "# Node definitions\n",
    "def task_master(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memories from the store and use them to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve profile memory from the store\n",
    "    namespace = (\"profile\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        user_profile = memories[0].value\n",
    "    else:\n",
    "        user_profile = None\n",
    "\n",
    "    # Retrieve task memory from the store\n",
    "    namespace = (\"todo\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    todo = \"\\n\".join(f\"{mem.value}\" for mem in memories)\n",
    "\n",
    "    # Retrieve custom instructions\n",
    "    namespace = (\"instructions\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        instructions = memories[0].value\n",
    "    else:\n",
    "        instructions = \"\"\n",
    "    \n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, todo=todo, instructions=instructions)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.bind_tools([UpdateMemory], parallel_tool_calls=True).invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def update_profile(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"profile\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"Profile\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = profile_extractor.invoke({\"messages\": updated_messages, \n",
    "                                         \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated profile\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "def update_todos(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"todo\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"ToDo\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # Initialize the spy for visibility into the tool calls made by Trustcall\n",
    "    spy = Spy()\n",
    "    \n",
    "    # Create the Trustcall extractor for updating the ToDo list \n",
    "    todo_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[ToDo],\n",
    "    tool_choice=tool_name,\n",
    "    enable_inserts=True\n",
    "    ).with_listeners(on_end=spy)\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = todo_extractor.invoke({\"messages\": updated_messages, \n",
    "                                    \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "        \n",
    "    # Respond to the tool call made in task_mAIstro, confirming the update\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "\n",
    "    # Extract the changes made by Trustcall and add the the ToolMessage returned to task_mAIstro\n",
    "    todo_update_msg = extract_tool_info(spy.called_tools, tool_name)\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": todo_update_msg, \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "def update_instructions(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    \n",
    "    namespace = (\"instructions\", user_id)\n",
    "\n",
    "    existing_memory = store.get(namespace, \"user_instructions\")\n",
    "        \n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = CREATE_INSTRUCTIONS.format(current_instructions=existing_memory.value if existing_memory else None)\n",
    "    new_memory = model.invoke([SystemMessage(content=system_msg)]+state['messages'][:-1] + [HumanMessage(content=\"Please update the instructions based on the conversation\")])\n",
    "\n",
    "    # Overwrite the existing memory in the store \n",
    "    key = \"user_instructions\"\n",
    "    store.put(namespace, key, {\"memory\": new_memory.content})\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated instructions\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "# Conditional edge\n",
    "def route_message(state: MessagesState, config: RunnableConfig, store: BaseStore) -> Literal[END, \"update_todos\", \"update_instructions\", \"update_profile\"]:\n",
    "\n",
    "    \"\"\"Reflect on the memories and chat history to decide whether to update the memory collection.\"\"\"\n",
    "    message = state['messages'][-1]\n",
    "    if len(message.tool_calls) ==0:\n",
    "        return END\n",
    "    else:\n",
    "        tool_call = message.tool_calls[0]\n",
    "        if tool_call['args']['update_type'] == \"user\":\n",
    "            return \"update_profile\"\n",
    "        elif tool_call['args']['update_type'] == \"todo\":\n",
    "            return \"update_todos\"\n",
    "        elif tool_call['args']['update_type'] == \"instructions\":\n",
    "            return \"update_instructions\"\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "# Create the graph + all nodes\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define the flow of the memory extraction process\n",
    "builder.add_node(task_master)\n",
    "builder.add_node(update_todos)\n",
    "builder.add_node(update_profile)\n",
    "builder.add_node(update_instructions)\n",
    "builder.add_edge(START, \"task_master\")\n",
    "builder.add_conditional_edges(\"task_master\", route_message)\n",
    "builder.add_edge(\"update_todos\", \"task_master\")\n",
    "builder.add_edge(\"update_profile\", \"task_master\")\n",
    "builder.add_edge(\"update_instructions\", \"task_master\")\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# We compile the graph with the checkpointer and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edfc18bc-373e-4dd0-a10f-a84d76cc50a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My name is Dd. I live in SAT with my wife Genevieve. I have a 1 year old puppy named Hungry and a 15 year old dog named Despereaux.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_NeNBixfRAABXokOmnkCXpzHv)\n",
      " Call ID: call_NeNBixfRAABXokOmnkCXpzHv\n",
      "  Args:\n",
      "    update_type: user\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated profile\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it! If there's anything else you'd like to share or need help with, just let me know.\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"Dd\"}}\n",
    "\n",
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"My name is Dd. I live in SAT with my wife Genevieve. I have a 1 year old puppy named Hungry and a 15 year old dog named Despereaux.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c955d8b-b719-4881-b10c-be218b933257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My wife asked me to book an appointment for Despereaux's comprehensive exam with the vet.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_PYvWhY5UKhPIxD44JNnVIqGx)\n",
      " Call ID: call_PYvWhY5UKhPIxD44JNnVIqGx\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': \"Book an appointment for Despereaux's comprehensive exam with the vet.\", 'mode': 'phone', 'time_to_complete': 15, 'bizhours_flag': True, 'solutions': [\"Call the vet's office to schedule an appointment\", \"Check the vet's online portal for appointment booking\"], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added the task to book an appointment for Despereaux's comprehensive exam with the vet to your ToDo list. If you need any help with it, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# User input for a ToDo\n",
    "input_messages = [HumanMessage(content=\"My wife asked me to book an appointment for Despereaux's comprehensive exam with the vet.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8bec14b-0b62-4f7a-9495-f92bfe5ae3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "When creating or updating ToDo items, include specific local businesses / vendors.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_JESEmHj3qeiYxZ14CSL1Wi1b)\n",
      " Call ID: call_JESEmHj3qeiYxZ14CSL1Wi1b\n",
      "  Args:\n",
      "    update_type: instructions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated instructions\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it! I'll make sure to include specific local businesses or vendors when creating or updating your ToDo items. If there's anything else you need, just let me know!\n"
     ]
    }
   ],
   "source": [
    "# User input to update instructions for creating ToDos\n",
    "input_messages = [HumanMessage(content=\"When creating or updating ToDo items, include specific local businesses / vendors.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "086357eb-1cbb-4af8-a57e-777ba7862d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "When creating or updating a ToDo item, ask the user for a deadline and mode if none are specified.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_Q1kS1uNH1IojSuRt7QG6RNkh)\n",
      " Call ID: call_Q1kS1uNH1IojSuRt7QG6RNkh\n",
      "  Args:\n",
      "    update_type: instructions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated instructions\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Understood! I'll ask for a deadline and mode if they're not specified when creating or updating a ToDo item. If you have any other preferences or need assistance, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "# User input to update instructions for creating ToDos\n",
    "input_messages = [HumanMessage(content=\"When creating or updating a ToDo item, ask the user for a deadline and mode if none are specified.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a5b609b-28b5-47cd-be1c-bfce6b304c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': \"Here are the updated instructions based on your feedback:\\n\\n<updated_instructions>\\n- When creating or updating ToDo items, include specific local businesses or vendors relevant to the task.\\n- If no deadline is specified, ask the user for a deadline.\\n- If no mode is specified, ask the user for a preferred mode of completion (e.g., phone, online, in-person).\\n</updated_instructions>\\n\\nIf there's anything else you'd like to adjust, just let me know!\"}\n"
     ]
    }
   ],
   "source": [
    "# Check for updated instructions\n",
    "user_id = \"Dd\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"instructions\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec432850-1c34-45c9-9c44-b1009dfa163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I need to bring the giant Jenga blocks from the yard to the garage.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_Ou4C5F9Jlx7NinJOzt0cgHyo)\n",
      " Call ID: call_Ou4C5F9Jlx7NinJOzt0cgHyo\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Bring the giant Jenga blocks from the yard to the garage.', 'mode': 'errand', 'time_to_complete': 10, 'solutions': ['Move the blocks manually', 'Use a cart or dolly to transport the blocks'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added the task to bring the giant Jenga blocks from the yard to the garage to your ToDo list. If you need any help or have more tasks to add, just let me know!\n"
     ]
    }
   ],
   "source": [
    "# User input for a ToDo\n",
    "input_messages = [HumanMessage(content=\"I need to bring the giant Jenga blocks from the yard to the garage.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "117879b1-e087-4c43-aca4-fd75dc87e408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the mode for this task?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The mode for the task \"Bring the giant Jenga blocks from the yard to the garage\" is set as an \"errand.\" If you need to change it or have any other questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# User input to validate ToDo item\n",
    "input_messages = [HumanMessage(content=\"What's the mode for this task?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54688887-6bbf-46c3-89f8-dd375c51dcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Change it to home.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_K0DLmxUF350pRZJ9QgKkyyWf)\n",
      " Call ID: call_K0DLmxUF350pRZJ9QgKkyyWf\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document d5bcde6a-61eb-4e95-82f8-fae91287f2ea updated:\n",
      "Plan: Change the mode of the task from 'errand' to 'home'.\n",
      "Added content: home\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've updated the mode for the task to \"home.\" If there's anything else you need, just let me know!\n"
     ]
    }
   ],
   "source": [
    "# User input to validate ToDo item\n",
    "input_messages = [HumanMessage(content=\"Change it to home.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "704e4e42-99e1-4882-9d0e-22fedd9cd35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "List all my todo items with the mode home.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are your ToDo items with the mode set to \"home\":\n",
      "\n",
      "1. **Task:** Bring the giant Jenga blocks from the yard to the garage.\n",
      "   - **Time to Complete:** 10 minutes\n",
      "   - **Solutions:** Move the blocks manually, Use a cart or dolly to transport the blocks\n",
      "   - **Status:** Not started\n",
      "\n",
      "If you need more details or have other tasks to manage, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# User input to validate ToDo items\n",
    "input_messages = [HumanMessage(content=\"List all my todo items with the mode home.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f43b342d-5971-4635-8fc6-08ba7f9be099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What about phone?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is your ToDo item with the mode set to \"phone\":\n",
      "\n",
      "1. **Task:** Book an appointment for Despereaux's comprehensive exam with the vet.\n",
      "   - **Time to Complete:** 15 minutes\n",
      "   - **Solutions:** Call the vet's office to schedule an appointment, Check the vet's online portal for appointment booking\n",
      "   - **Status:** Not started\n",
      "\n",
      "Let me know if there's anything else you need!\n"
     ]
    }
   ],
   "source": [
    "# User input to validate ToDo item\n",
    "input_messages = [HumanMessage(content=\"What about phone?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "877a97e5-beaa-47c9-8dff-6a96fac4f015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What about errand?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It looks like there are no ToDo items with the mode set to \"errand\" at the moment. If you have any tasks to add or need further assistance, just let me know!\n"
     ]
    }
   ],
   "source": [
    "# User input to validate ToDo item\n",
    "input_messages = [HumanMessage(content=\"What about errand?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20cca56c-c5fc-4223-964b-3643f7e9306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Dd', 'location': 'SAT', 'job': None, 'connections': ['Genevieve', 'Hungry', 'Despereaux'], 'interests': []}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"Dd\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"profile\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2252e9c6-1d49-41e0-a15e-0440c6457ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I love eating tacos!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_sls43wzNiX9RveYvbNpFUEM3)\n",
      " Call ID: call_sls43wzNiX9RveYvbNpFUEM3\n",
      "  Args:\n",
      "    update_type: user\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated profile\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Tacos are delicious! If you ever need recommendations for taco places or anything else, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# User input to validate profile item\n",
    "input_messages = [HumanMessage(content=\"I love eating tacos!\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31f201e8-ffb0-476f-995a-4b832d49ed52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Dd', 'location': 'SAT', 'job': None, 'connections': ['Genevieve', 'Hungry', 'Despereaux'], 'interests': ['eating tacos']}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"Dd\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"profile\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "909edfcf-ea10-42d8-8dd1-51db5d36a75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "For the jenga blocks, I need it done before this Sunday.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_EYRJnOAtRKJXRvSEcWjov00h)\n",
      " Call ID: call_EYRJnOAtRKJXRvSEcWjov00h\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document d5bcde6a-61eb-4e95-82f8-fae91287f2ea updated:\n",
      "Plan: Add a deadline to the task to ensure it is completed before Sunday.\n",
      "Added content: 2025-01-19T23:59:59\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've updated the task to include a deadline for completion before this Sunday. If there's anything else you need, just let me know!\n"
     ]
    }
   ],
   "source": [
    "# User input to update an existing ToDo\n",
    "input_messages = [HumanMessage(content=\"For the jenga blocks, I need it done before this Sunday.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae418b8b-340b-4b78-a1e3-8713f50ce623",
   "metadata": {},
   "source": [
    "## NEW THREAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5287e0f2-527e-44df-b098-725b992c1fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I have 30 minutes, what tasks can I get done?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You have two tasks on your ToDo list:\n",
      "\n",
      "1. **Book an appointment for Despereaux's comprehensive exam with the vet.**\n",
      "   - Estimated time to complete: 15 minutes\n",
      "   - Mode: Phone\n",
      "   - Solutions: Call the vet's office to schedule an appointment, or check the vet's online portal for appointment booking.\n",
      "\n",
      "2. **Bring the giant Jenga blocks from the yard to the garage.**\n",
      "   - Estimated time to complete: 10 minutes\n",
      "   - Mode: Home\n",
      "   - Solutions: Move the blocks manually, or use a cart or dolly to transport the blocks.\n",
      "\n",
      "You can complete both tasks within 30 minutes. Would you like to start with one of these tasks?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"Dd\"}}\n",
    "\n",
    "# Chat with the chatbot\n",
    "input_messages = [HumanMessage(content=\"I have 30 minutes, what tasks can I get done?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0c4faed-0ae7-497c-b4f8-7d37b6913326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Task 1 cannot be done today because it's past business hours.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it! Since it's past business hours, you can focus on the second task:\n",
      "\n",
      "- **Bring the giant Jenga blocks from the yard to the garage.**\n",
      "  - Estimated time to complete: 10 minutes\n",
      "\n",
      "You can get this task done now. Let me know if you need any help!\n"
     ]
    }
   ],
   "source": [
    "# Chat with the chatbot\n",
    "input_messages = [HumanMessage(content=\"Task 1 cannot be done today because it's past business hours.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1089eaa-78e0-4a31-8196-202cb6a91827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "When listing todo items, do not include tasks that can only be done during busines hours if it's past 4 PM.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_xU2LfJPX69y0htDoFNPoRtw4)\n",
      " Call ID: call_xU2LfJPX69y0htDoFNPoRtw4\n",
      "  Args:\n",
      "    update_type: instructions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated instructions\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've updated the instructions to exclude tasks that can only be done during business hours if it's past 4 PM when listing ToDo items. If there's anything else you'd like to adjust, just let me know!\n"
     ]
    }
   ],
   "source": [
    "# Chat with the chatbot\n",
    "input_messages = [HumanMessage(content=\"When listing todo items, do not include tasks that can only be done during busines hours if it's past 4 PM.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "000a40b4-b614-4d91-b14a-5222d580144a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I have 15 minutes, what tasks can I get done?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You can work on the following task:\n",
      "\n",
      "- **Bring the giant Jenga blocks from the yard to the garage.**\n",
      "  - Estimated time to complete: 10 minutes\n",
      "\n",
      "This task can be completed within your available 15 minutes. Let me know if you need any assistance!\n"
     ]
    }
   ],
   "source": [
    "# Chat with the chatbot\n",
    "input_messages = [HumanMessage(content=\"I have 15 minutes, what tasks can I get done?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fdacad8-97ef-47a4-aa9a-036fa168942c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you remind me about our past conversations?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here's a summary of our past interactions:\n",
      "\n",
      "1. **User Profile:**\n",
      "   - Name: Dd\n",
      "   - Location: SAT\n",
      "   - Connections: Genevieve, Hungry, Despereaux\n",
      "   - Interests: Eating tacos\n",
      "\n",
      "2. **ToDo List:**\n",
      "   - Book an appointment for Despereaux's comprehensive exam with the vet (cannot be done after business hours).\n",
      "   - Bring the giant Jenga blocks from the yard to the garage.\n",
      "\n",
      "3. **Instructions for ToDo List:**\n",
      "   - Include specific local businesses or vendors relevant to the task.\n",
      "   - Ask for a deadline if none is specified.\n",
      "   - Ask for a preferred mode of completion if none is specified.\n",
      "   - Do not include tasks that can only be done during business hours if it is past 4 PM.\n",
      "\n",
      "If there's anything specific you'd like to revisit or update, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "# Chat with the chatbot\n",
    "input_messages = [HumanMessage(content=\"Can you remind me about our past conversations?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824b1aa-edaa-43ca-a06b-6845c4a3fa46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
